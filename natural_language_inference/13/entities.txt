153	0	4	RACE
153	11	26	key competitors
153	27	30	are
153	35	76	Stanford Attention Reader ( Stanford AR )
153	79	108	Gated Attention Reader ( GA )
153	115	146	Dynamic Fusion Networks ( DFN )
157	0	9	Search QA
157	16	40	main competitor baseline
157	41	43	is
157	48	60	AMANDA model
163	51	60	baselines
163	61	64	are
163	67	120	context - less sequence to sequence ( seq2seq ) model
163	123	126	ASR
163	131	136	BiDAF
176	3	12	implement
176	13	23	all models
176	24	26	in
176	27	37	TensorFlow
177	0	15	Word embeddings
177	20	36	initialized with
177	37	56	300d Glo Ve vectors
177	65	88	not fine - tuned during
177	89	97	training
178	0	12	Dropout rate
178	16	29	tuned amongst
178	30	49	{ 0.1 , 0.2 , 0.3 }
178	24	26	on
178	53	63	all layers
178	64	73	including
178	78	93	embedding layer
187	4	14	batch size
187	18	24	set to
187	25	34	64/256/32
188	4	28	maximum sequence lengths
188	29	32	are
188	33	45	500/200/1100
185	3	8	adopt
185	13	27	Adam optimizer
185	28	32	with
185	35	48	learning rate
185	49	51	of
185	52	71	0.0003/ 0.001/0.001
185	72	75	for
190	54	62	based on
190	65	76	TitanXP GPU
190	27	49	all runtime benchmarks
190	15	22	trained
190	0	10	All models
24	17	24	propose
24	27	52	new compositional encoder
24	72	90	used in - place of
24	91	112	standard RNN encoders
24	116	124	serve as
24	127	137	new module
24	146	162	complementary to
24	163	192	existing neural architectures
25	0	25	Our proposed MRU encoders
25	26	32	learns
25	33	47	gating vectors
25	48	51	via
25	52	91	multiple contract - and - expand layers
25	34	36	at
25	95	123	multiple dilated resolutions
28	4	30	k document representations
28	24	26	at
28	36	69	multiple ranges and n-gram blocks
28	81	106	combined and modeled with
28	107	129	fully connected layers
28	130	137	to form
28	142	166	final compositional gate
28	177	189	applied onto
28	194	217	original input document
26	18	26	compress
26	31	45	input document
26	49	113	arbitrary k times at multi-ranges ( e.g. , 1 , 2 , 4 , 10 , 25 )
26	114	118	into
26	121	170	neural bag - of - words ( summed ) representation
27	29	43	passed through
27	44	72	affine transformation layers
27	82	96	re-expanded to
27	101	125	original sequence length
2	26	47	Machine Comprehension
4	88	116	machine comprehension ( MC )
19	90	92	MC
195	21	23	on
195	24	28	RACE
195	21	23	on
191	21	36	6 % improvement
191	44	60	RACE - H dataset
191	65	82	1.8 % improvement
191	37	39	on
191	90	106	RACE - M dataset
197	16	23	achieve
197	24	46	comparable performance
197	47	49	to
197	50	60	each other
197	69	88	GRU and LSTM models
197	89	100	do not have
197	103	119	competitive edge
197	136	146	no encoder
197	155	163	achieves
197	164	188	comparable 1 performance
197	47	49	to
197	192	195	DFN
198	13	41	ensemble of Sim . MRU models
198	42	49	achieve
198	50	84	state - of - the - art performance
198	85	87	on
198	92	104	RACE dataset
198	107	116	achieving
198	121	134	overall score
198	22	24	of
198	138	144	53.3 %
200	55	77	Narrative QA benchmark
201	11	23	observe that
201	24	32	300d MRU
201	33	44	can achieve
201	45	67	comparable performance
201	68	72	with
201	73	78	BiDAF
202	5	18	compared with
202	21	27	BiLSTM
202	28	30	of
202	31	64	equal output dimensions ( 150 d )
202	70	79	find that
202	84	93	MRU model
202	94	102	performs
202	103	116	competitively
202	14	18	with
202	124	149	less than 1 % deprovement
202	150	156	across
202	157	168	all metrics
204	4	18	performance of
204	19	28	our model
204	29	31	is
204	32	52	significantly better
204	53	57	than
204	58	73	300d LSTM model
204	80	90	also being
204	91	111	significantly faster
208	14	24	MRU - LSTM
208	25	50	significantly outperforms
208	51	61	all models
208	64	73	including
208	74	79	BiDAF
209	0	23	Performance improvement
209	24	28	over
209	33	53	vanilla BiLSTM model
209	54	65	ranges from
209	66	75	1 % ? 3 %
209	76	82	across
209	83	94	all metrics
