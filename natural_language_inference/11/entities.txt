101	0	10	All models
101	15	22	trained
101	23	37	end - to - end
101	38	45	jointly
101	46	50	with
101	55	72	refinement module
101	73	78	using
101	81	95	dimensionality
101	96	98	of
101	99	106	n = 300
101	107	110	for
101	111	143	all but the TriviaQA experiments
101	157	170	had to reduce
101	171	179	n to 150
101	180	186	due to
101	187	205	memory constraints
102	0	13	All baselines
102	14	24	operate on
102	29	54	unrefined word embeddings
103	0	3	For
103	8	27	DQA baseline system
103	31	34	add
103	39	44	lemma
103	17	19	in
103	50	74	question feature ( liq )
21	19	26	develop
21	29	45	new architecture
21	46	75	for dynamically incorporating
21	76	105	external background knowledge
21	62	64	in
21	109	119	NLU models
22	87	110	supplementary knowledge
22	114	128	retrieved from
22	129	155	external knowledge sources
22	174	184	ConceptNet
22	189	198	Wikipedia
22	204	229	assist with understanding
22	230	241	text inputs
25	25	28	are
25	34	41	used as
25	42	47	input
25	48	50	to
25	53	85	task - specific NLU architecture
24	4	33	retrieved supplementary texts
24	38	56	read together with
24	61	72	task inputs
24	73	75	by
24	79	101	initial reading module
24	102	107	whose
24	108	115	outputs
24	120	156	contextually refined word embeddings
26	4	46	initial reading module and the task module
26	47	57	are learnt
26	58	82	jointly , end - to - end
2	47	57	Neural NLU
4	96	141	neural natural language understanding ( NLU )
139	6	12	yields
139	13	47	further , significant improvements
139	48	50	on
139	51	59	TriviaQA
139	62	84	slightly outperforming
139	89	119	current state of the art model
148	25	40	RTE experiments
149	17	32	introduction of
149	33	56	our refinement strategy
149	57	76	almost always helps
149	84	100	with and without
149	101	119	external knowledge
150	0	14	When providing
150	15	46	additional background knowledge
150	47	51	from
150	52	62	ConceptNet
150	65	88	our BiLSTM based models
150	89	110	improve substantially
150	123	142	ESIM - based models
150	89	96	improve
150	151	158	only on
150	163	194	more difficult MultiNLI dataset
151	60	70	our models
151	71	77	acquit
151	89	99	quite well
151	100	102	on
151	107	125	MultiNLI benchmark
151	132	145	competitively
151	100	102	on
151	153	167	SNLI benchmark
158	15	49	both ESIM and our BiL - STM models
158	55	67	trained with
158	68	77	knowledge
158	78	82	from
158	83	93	ConceptNet
158	98	110	sensitive to
158	115	124	semantics
158	125	127	of
158	132	151	provided assertions
155	6	15	find that
155	25	38	little impact
155	39	47	of using
155	48	66	external knowledge
155	67	69	on
155	74	82	RTE task
155	83	87	with
155	88	92	ESIM
160	14	24	increasing
160	29	37	coverage
160	38	40	of
160	41	51	assertions
160	14	16	in
160	55	65	ConceptNet
160	72	89	most likely yield
160	90	110	improved performance
160	116	134	without retraining
160	135	145	our models
