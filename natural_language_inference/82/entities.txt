77	0	17	For preprocessing
77	23	30	segment
77	31	40	sentences
77	41	43	at
77	44	61	punctuation marks
77	64	65	.
77	72	73	!
77	84	85	?
79	3	8	train
79	13	18	model
79	21	25	with
79	26	44	hyper - parameters
79	45	58	lightly tuned
79	59	61	on
79	66	80	validation set
24	49	58	implement
24	61	67	reader
24	73	91	dynamically builds
24	92	115	meaning representations
24	116	119	for
24	120	131	each entity
24	134	163	by gathering and accumulating
24	164	175	information
24	31	33	on
24	125	131	entity
24	191	202	as it reads
24	205	213	document
2	58	73	Machine Reading
81	14	27	Max - pooling
81	53	73	drastically improves
81	74	85	performance
104	4	29	99 % confidence intervals
104	30	32	of
104	37	44	results
104	30	32	of
104	48	100	full DER Network and the one initialized by word2vec
104	10	12	on
104	108	116	test set
104	117	121	were
104	122	139	[ 0.700 , 0.740 ]
104	144	161	[ 0.708 , 0.749 ]
101	13	22	note that
101	23	35	initializing
101	36	45	our model
101	46	50	with
101	51	75	pre-trained word vectors
101	79	81	is
101	82	89	helpful
103	23	32	our model
103	35	51	full DER Network
103	54	59	shows
103	64	76	best results
103	77	88	compared to
103	89	119	several previous reader models
